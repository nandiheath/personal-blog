<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>踩坑日記</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.nandiheath.com/"/>
  <updated>2019-09-18T09:13:44.717Z</updated>
  <id>https://blog.nandiheath.com/</id>
  
  <author>
    <name>Nandi Wong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>利用TravisCI直接發佈靜態網頁到Github Pages上</title>
    <link href="https://blog.nandiheath.com/2019/09/18/travisci-publish-github-pages/"/>
    <id>https://blog.nandiheath.com/2019/09/18/travisci-publish-github-pages/</id>
    <published>2019-09-18T09:13:44.717Z</published>
    <updated>2019-09-18T09:13:44.717Z</updated>
    
    <content type="html"><![CDATA[<p>github 有一個工具讓你可以存放一些簡單的靜態網頁</p><ul><li><a href="https://pages.github.com/" target="_blank" rel="noopener">Github Pages</a></li><li><a href="https://help.github.com/articles/what-is-github-pages/" target="_blank" rel="noopener">什麼是Github Pages</a></li></ul><p>而且是完全免費！(當然有幾個附帶的條件)</p><ul><li>1GB容量</li><li>只支持靜態網頁(html/css/js等)</li><li>每月100GB流量</li><li><a href="https://help.github.com/articles/what-is-github-pages/" target="_blank" rel="noopener">…</a></li></ul><p>只要你在github的repo中放上你的網頁 (如index.html)<br>你就可以在 https://[username].github.io/[repo_name] 中看到你放上去的網站<br>亦可以設定一個首頁<br>只要repo的名字是 <strong>[username].github.io</strong><br>你就可以直接在 <code>https://[username].github.io</code> 看到你的網站了</p><a id="more"></a><h2 id="Github設定"><a href="#Github設定" class="headerlink" title="Github設定"></a>Github設定</h2><p>Github Page 預設是把你<code>master</code>　branch中的檔案發佈到站上<br>但同時亦提供了另外幾種方法去<a href="https://help.github.com/articles/configuring-a-publishing-source-for-github-pages/" target="_blank" rel="noopener">設定發佈的來源</a></p><blockquote><p>You can configure GitHub Pages to publish your site’s source files from <code>master</code>, <code>gh-pages</code>, or a <code>/docs</code> folder on your <code>master</code> branch for Project Pages and other Pages sites that meet certain criteria.</p></blockquote><p>因為我的repo有其他的源碼<br>所以這邊我就選了用gh-pages來發佈</p><p><img src="/images/travisci-publish-github-pages-01.png" alt=""><em>只要在source那邊選用gh-pages來發佈就可以了</em></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先clone repo</span></span><br><span class="line">git <span class="built_in">clone</span> git@github.com:[username]/[repo].git</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="built_in">cd</span> [repository]</span><br><span class="line"></span><br><span class="line"><span class="comment"># checkout 一條新的orphan branch</span></span><br><span class="line">git checkout --orphan gh-pages</span><br><span class="line"></span><br><span class="line"><span class="comment"># 並把他推到github 上</span></span><br><span class="line">git push origin gh-pages</span><br><span class="line"></span><br><span class="line"><span class="comment"># 之後的網站內容都放到gh-pages這條branch 當中</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><a href="https://help.github.com/articles/creating-project-pages-using-the-command-line/" target="_blank" rel="noopener"><em>Github上的教學</em></a></p><p>這邊要用到orphan branch的原因是因為靜態網站並不需要你的源碼<br>我們只需把travis設定成把網站的源碼build起來之後加到這條branch中就可以了<br>其中的檔案跟本來的master branch是完全獨立的<br>簡單來說就是<code>master</code> branch中只有源碼，build folder是處於<code>.gitignore</code>的狀態<br>而<code>gh-pages</code>當中只有每次ci build完的網站，跟<code>master</code> branch是完全沒有關連</p><p><img src="/images/travisci-publish-github-pages-02.png" alt=""><em>所以你會在git中看到以上的畫面</em></p><h2 id="TravisCI-設定"><a href="#TravisCI-設定" class="headerlink" title="TravisCI 設定"></a>TravisCI 設定</h2><p>下一步就是設定travis-ci<br>這裡是在deploy stage中加入了以下的設定</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- stage:</span> <span class="string">deploy</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">npm</span> <span class="string">run</span> <span class="string">build</span> <span class="comment"># build vue</span></span><br><span class="line"><span class="attr">  deploy:</span></span><br><span class="line"><span class="attr">    provider:</span> <span class="string">pages</span> <span class="comment">#</span></span><br><span class="line"><span class="attr">    skip-cleanup:</span> <span class="literal">true</span> </span><br><span class="line"><span class="attr">    github-token:</span> <span class="string">$GITHUB_TOKEN</span>  <span class="comment"># 在github中生成的Personal access token</span></span><br><span class="line"><span class="attr">    keep-history:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    local-dir:</span> <span class="string">web/dist</span> <span class="comment"># build完之後的目錄，直接從repo root開始計算</span></span><br><span class="line"><span class="attr">    on:</span></span><br><span class="line"><span class="attr">      branch:</span> <span class="string">master</span> <span class="comment">#　只有master branch才把網站發佈到github page上</span></span><br></pre></td></tr></table></figure><p>然後再在travisci中設定你的github access token<code>GITHUB_TOKEN</code>就完成了</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;github 有一個工具讓你可以存放一些簡單的靜態網頁&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://pages.github.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://help.github.com/articles/what-is-github-pages/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;什麼是Github Pages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而且是完全免費！(當然有幾個附帶的條件)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1GB容量&lt;/li&gt;
&lt;li&gt;只支持靜態網頁(html/css/js等)&lt;/li&gt;
&lt;li&gt;每月100GB流量&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://help.github.com/articles/what-is-github-pages/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;…&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;只要你在github的repo中放上你的網頁 (如index.html)&lt;br&gt;你就可以在 https://[username].github.io/[repo_name] 中看到你放上去的網站&lt;br&gt;亦可以設定一個首頁&lt;br&gt;只要repo的名字是 &lt;strong&gt;[username].github.io&lt;/strong&gt;&lt;br&gt;你就可以直接在 &lt;code&gt;https://[username].github.io&lt;/code&gt; 看到你的網站了&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="ci" scheme="https://blog.nandiheath.com/categories/devops/ci/"/>
    
    
      <category term="ci" scheme="https://blog.nandiheath.com/tags/ci/"/>
    
      <category term="travisci" scheme="https://blog.nandiheath.com/tags/travisci/"/>
    
      <category term="github" scheme="https://blog.nandiheath.com/tags/github/"/>
    
      <category term="github-pages" scheme="https://blog.nandiheath.com/tags/github-pages/"/>
    
  </entry>
  
  <entry>
    <title>cert-manager-with-kubernetes-ingress</title>
    <link href="https://blog.nandiheath.com/2019/03/29/cert-manager-with-kubernetes-ingress/"/>
    <id>https://blog.nandiheath.com/2019/03/29/cert-manager-with-kubernetes-ingress/</id>
    <published>2019-03-29T07:15:19.000Z</published>
    <updated>2019-09-18T09:13:44.707Z</updated>
    
    <content type="html"><![CDATA[<p>說起免費的HTTPS cert<br>很多人都會用let’s encrypt的服務<br>原因是簡單，易用<br>在VM上裝一個script然後簡單配置一下nginx就可以生成一張數個月的ssl certificate</p><p>但當來到kubernetes就有點麻煩<br>原因是你配置的服務很多可能都不在同一部機上<br>當你生成了一張ssl cert之後可能要手動去更新相應的配置<br>而且要建立自動更新難度更大</p><p>所以這時侯就可以用到cert-manager了<br><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">https://github.com/jetstack/cert-manager</a><br>他是一個k8s的addon<br>可以生成一系列的resources去幫以上的配置自動化<br>而且除了let’s encrypt之外也支持其他的ssl cert發行者</p><p>如果是用let’s encrypt的話<br>原理大致如下</p><p>首先你會生成一個ingress<br>並加一些特殊的annotation去表明你想cert-manager去幫你配置ssl cert<br>在這邊你需要先指定一個secret，讓cert-manager把配置好的ssl存放在裡面</p><p>之後cert-manager接收到相應的事件觸發後就會開始工作流程<br>他會先建立一張self-signed的ssl cert並放在該secret裡面<br>這個時侯你去訪問ingress就會發現https已經能夠使用<br>但ssl cert是不被瀏覽器信任的</p><p>然後cert-manager會建立一個暫時的ingress<br>去接收來自let’s encrypt的acme challenge<br>去證明你擁有該域名<br>如果驗證成功的話就會生成一張正確的ssl cert並更新secret<br>之後你再訪問https就會看到鎖頭了</p><p>實際操作這邊就懶得說了<br>直接看這裡<br><a href="https://docs.cert-manager.io/en/latest/tutorials/acme/quick-start/index.html" target="_blank" rel="noopener">https://docs.cert-manager.io/en/latest/tutorials/acme/quick-start/index.html</a></p><p>有一點範例沒有說清楚<br>但卻至關重要，因為你如你是用nginx-ingress的話好有可能會出現這個問題</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">example</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">certmanager.k8s.io/cluster-issuer:</span> <span class="string">"letsencrypt-prod"</span></span><br><span class="line">    <span class="string">certmanager.k8s.io/acme-challenge-type:</span> <span class="string">http01</span></span><br><span class="line">    <span class="string">certmanager.k8s.io/acme-http01-edit-in-place:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  tls:</span></span><br><span class="line"><span class="attr">  - hosts:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">a1.example.com</span></span><br><span class="line"><span class="attr">    secretName:</span> <span class="string">al-example-com-tls</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">a1.example.com</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">      - path:</span> <span class="string">/api</span></span><br><span class="line"><span class="attr">        backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">backend</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>當中<code>certmanager.k8s.io/acme-http01-edit-in-place: &quot;true&quot;</code><br>這句是很重要的</p><p>因為nginx-ingress是不能如時接受兩個ingress resources<br>就是如果你有兩個ingress，而兩個都有同一個host的話<br>只有其中一個能運行，另一個則無效<br>大概猜到原因是nginx的配置有關<br>因為nginx-ingress-controller會接收ingress的配置並且在<code>/etc/nginx/conf.d</code>中生成配置文件</p><p>而cert-manager預設是acme-challenger會生成另一個ingress資源出來<br>所以你要把這個配置設定成true，目的就是希望cert-manager去更改原本的ingress<br>且不是新開另一個出來</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;說起免費的HTTPS cert&lt;br&gt;很多人都會用let’s encrypt的服務&lt;br&gt;原因是簡單，易用&lt;br&gt;在VM上裝一個script然後簡單配置一下nginx就可以生成一張數個月的ssl certificate&lt;/p&gt;
&lt;p&gt;但當來到kubernetes就有點麻煩&lt;
      
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/tags/kubernetes/"/>
    
      <category term="aws" scheme="https://blog.nandiheath.com/tags/aws/"/>
    
      <category term="ingress" scheme="https://blog.nandiheath.com/tags/ingress/"/>
    
      <category term="cert-manager" scheme="https://blog.nandiheath.com/tags/cert-manager/"/>
    
      <category term="letsencrypt" scheme="https://blog.nandiheath.com/tags/letsencrypt/"/>
    
  </entry>
  
  <entry>
    <title>deploy-npm-package-with-travis</title>
    <link href="https://blog.nandiheath.com/2019/03/19/deploy-npm-package-with-travis/"/>
    <id>https://blog.nandiheath.com/2019/03/19/deploy-npm-package-with-travis/</id>
    <published>2019-03-19T09:14:03.000Z</published>
    <updated>2019-09-18T09:13:44.709Z</updated>
    
    <content type="html"><![CDATA[<h2 id="方法一-利用travis內置的deploy-provider"><a href="#方法一-利用travis內置的deploy-provider" class="headerlink" title="方法一: 利用travis內置的deploy provider"></a>方法一: 利用travis內置的deploy provider</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Login the travis.com</span></span><br><span class="line">travis login --com</span><br><span class="line"></span><br><span class="line"><span class="comment"># encrypt the API_KEY for travis API</span></span><br><span class="line">travis encrypt [NPM_API_KEY] --com --add <span class="string">'deploy.api_key'</span></span><br></pre></td></tr></table></figure><p>這個命令會在.travis-ci.yaml中加入一個deploy的secret<br>若果是公開的repo最好把它抽出來以環境變數的形式去載入</p><p>但這個如果用環境變數的話不知為何總是跑出<figure class="highlight plain"><figcaption><span>Unauthorized you must be logged in to publish packages travis```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">搞了一輪之後決定用第二個方法</span><br><span class="line"></span><br><span class="line">## 方法二: deploy script及利用.npmrc</span><br><span class="line"></span><br><span class="line">新增一個deploy.sh</span><br><span class="line">```bash</span><br><span class="line">echo &quot;//registry.npmjs.org/:_authToken=$&#123;NPM_API_TOKEN&#125;&quot; &gt; $HOME/.npmrc</span><br><span class="line"></span><br><span class="line">npm publish</span><br></pre></td></tr></table></figure></p><p>這會將環境變數寫成npmrc<br>而npm script會利用它來認證並發佈</p><p>檔案如下</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">language:</span> <span class="string">node_js</span></span><br><span class="line"><span class="attr">node_js:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">'11'</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">'10'</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">'8'</span></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">deploy</span></span><br><span class="line"><span class="attr">  if:</span> <span class="string">branch</span> <span class="string">=</span> <span class="string">master</span></span><br><span class="line"><span class="attr">cache:</span> <span class="string">npm</span></span><br><span class="line"><span class="comment"># Use script instead of npm provider as it cannot auth via env variables?</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="attr">  provider:</span> <span class="string">script</span></span><br><span class="line"><span class="attr">  script:</span> <span class="string">"./deploy.sh"</span></span><br><span class="line"><span class="attr">  skip_cleanup:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># only on tagged builds</span></span><br><span class="line"><span class="attr">  on:</span></span><br><span class="line"><span class="attr">    tags:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Send an email when a new version is released</span></span><br><span class="line"><span class="attr">notifications:</span></span><br><span class="line"><span class="attr">  email:</span></span><br><span class="line"><span class="attr">    recipients:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"$NPM_EMAIL"</span></span><br><span class="line"><span class="attr">    on_success:</span> <span class="string">change</span></span><br><span class="line"><span class="attr">    on_failure:</span> <span class="string">always</span></span><br></pre></td></tr></table></figure><h2 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h2><p>- </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;方法一-利用travis內置的deploy-provider&quot;&gt;&lt;a href=&quot;#方法一-利用travis內置的deploy-provider&quot; class=&quot;headerlink&quot; title=&quot;方法一: 利用travis內置的deploy provider&quot;
      
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="ci" scheme="https://blog.nandiheath.com/categories/devops/ci/"/>
    
    
      <category term="travis" scheme="https://blog.nandiheath.com/tags/travis/"/>
    
      <category term="ci" scheme="https://blog.nandiheath.com/tags/ci/"/>
    
      <category term="npm" scheme="https://blog.nandiheath.com/tags/npm/"/>
    
  </entry>
  
  <entry>
    <title>gRPC在kubernetes的小問題</title>
    <link href="https://blog.nandiheath.com/2019/02/26/grpc-in-kubernetes/"/>
    <id>https://blog.nandiheath.com/2019/02/26/grpc-in-kubernetes/</id>
    <published>2019-02-26T09:55:43.000Z</published>
    <updated>2019-09-18T09:13:44.714Z</updated>
    
    <content type="html"><![CDATA[<p>事緣每隔一段時間deploy後<br>總有一部份pod在連接其他pod的gRPC時會報錯<br>發生機率極低</p><p>經過一大堆的測試後卻又不能復現<br>包括各種DNS/k8s上的測試</p><p>但我查看kube-proxy的log後<br>相信是跟gRPC內置的dns cache機制有關係<br>因為每次狀態發生時都跟kube-proxy的重啟有關係<br>因為未明原因導致kube-proxy重啟 &gt; 重啟後一些routing的改變 &gt;<br>某些pod的internal ip改變了 &gt; gRPC的DNS仍舊指向舊的pod ip &gt; 連不上</p><p>用比較暴力的方法去解決<br>就是利用gRPC的DEADLINE機制<br>再加上設定liveness probe<br>每隔一段時間k8s會訪問你的狀態<br>若果是連續幾次都timeout的話就會把pod砍掉重啟</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">const</span> deadline = <span class="keyword">new</span> <span class="built_in">Date</span>().setSeconds(<span class="keyword">new</span> <span class="built_in">Date</span>().getSeconds() + GRPC_TIMEOUT_SECONDS);</span><br><span class="line">gRPCClient.query(query, &#123; deadline &#125;, (err, res) =&gt; &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>當然上面是一個很危險的方法<br>若果連線狀態很差可能會一直重啟<br>造成服務不穩的情況<br>更好的做法或者是利用第三方的service discovery<br>例如Istio或者linkerd等service mesh<br>或者將來有時間可以再研究一下…</p><h2 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h2><ul><li><a href="https://kubernetes.io/blog/2018/11/07/grpc-load-balancing-on-kubernetes-without-tears/" target="_blank" rel="noopener">https://kubernetes.io/blog/2018/11/07/grpc-load-balancing-on-kubernetes-without-tears/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;事緣每隔一段時間deploy後&lt;br&gt;總有一部份pod在連接其他pod的gRPC時會報錯&lt;br&gt;發生機率極低&lt;/p&gt;
&lt;p&gt;經過一大堆的測試後卻又不能復現&lt;br&gt;包括各種DNS/k8s上的測試&lt;/p&gt;
&lt;p&gt;但我查看kube-proxy的log後&lt;br&gt;相信是跟gRPC內
      
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/tags/kubernetes/"/>
    
      <category term="dns" scheme="https://blog.nandiheath.com/tags/dns/"/>
    
      <category term="grpc" scheme="https://blog.nandiheath.com/tags/grpc/"/>
    
  </entry>
  
  <entry>
    <title>Interview然後知不足</title>
    <link href="https://blog.nandiheath.com/2019/02/25/interview/"/>
    <id>https://blog.nandiheath.com/2019/02/25/interview/</id>
    <published>2019-02-25T07:53:32.000Z</published>
    <updated>2019-09-18T09:13:44.714Z</updated>
    
    <content type="html"><![CDATA[<p>一連參與了兩間公司的面試，雖然驚驚險險的走到最後一輪<br>但過程中深深感受到自己的不足<br>希望未來可以改善(吧)</p><h2 id="Fast-Coder"><a href="#Fast-Coder" class="headerlink" title="Fast Coder"></a>Fast Coder</h2><p>之前就算做startup也好<br>現在做的app也好<br>很多時侯都貪圖快捷方便<br>沒有用很正規的寫法/流程<br>一切以結果為先</p><p>我深信很多香港的公司也是這樣<br>尤其是vendor<br>但這不是一個藉口<br>TDD/BDD對software的好處遠遠大於弊處<br>而且缺乏長遠的計劃也的確是一個咎病<br>得改</p><h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><ul><li>先想好，後再落手做</li><li>多一點testing</li></ul><h2 id="英文差"><a href="#英文差" class="headerlink" title="英文差"></a>英文差</h2><p>um…<br>只能說多聽多講<br>畢竟這兩年普通話突飛猛進也是因為每天用普通話跟內地同事溝通…</p><p>## </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一連參與了兩間公司的面試，雖然驚驚險險的走到最後一輪&lt;br&gt;但過程中深深感受到自己的不足&lt;br&gt;希望未來可以改善(吧)&lt;/p&gt;
&lt;h2 id=&quot;Fast-Coder&quot;&gt;&lt;a href=&quot;#Fast-Coder&quot; class=&quot;headerlink&quot; title=&quot;Fast 
      
    
    </summary>
    
      <category term="personal" scheme="https://blog.nandiheath.com/categories/personal/"/>
    
    
  </entry>
  
  <entry>
    <title>選擇kubenetes的node type</title>
    <link href="https://blog.nandiheath.com/2019/02/21/choose-k8s-node-type-wisely/"/>
    <id>https://blog.nandiheath.com/2019/02/21/choose-k8s-node-type-wisely/</id>
    <published>2019-02-21T03:39:07.000Z</published>
    <updated>2019-09-18T09:13:44.709Z</updated>
    
    <content type="html"><![CDATA[<p>公司的集群一直都在用t2.medium<br>原因是t2系列中可累積的CPU credit非常實用<br>詳情可參看 <a href="/2018/09/19/aws-t2-medium/" title="AWS中t2.medium的二三事">AWS中t2.medium的二三事</a><br>而且medium的內存(4G)也夠跑一定數量的pod<br>比較比相當不錯</p><p>但最近參考了其他人的做法<br>把node type從medium轉換成xlarge之後<br>node的數量大減之餘，價格亦有相當的減少<br>所以希望在此分享一下心得</p><h2 id="為什麼t2-xlarge會比t2-medium好"><a href="#為什麼t2-xlarge會比t2-medium好" class="headerlink" title="為什麼t2.xlarge會比t2.medium好"></a>為什麼t2.xlarge會比t2.medium好</h2><p>如果單看價錢的話<br>t2.xlarge的價錢是t2.medium的4倍<br>但只有2倍於medium(4個vCPU), cpu credit也沒有去到4倍<br><img src="/images/aws-pricing.png" alt=""></p><p>這樣看的話只有內存才算是真的4倍<br>那為什麼說xlarge會比medium利用率更好呢？</p><a id="more"></a><p>我們首先要看一下kubenetes每個node的一些設定</p><h3 id="預設服務"><a href="#預設服務" class="headerlink" title="預設服務"></a>預設服務</h3><p>每個node本身都會在其之上跑一些預設的服務<br>例如kubeproxy<br><img src="/images/kube-proxy-resource.png" alt=""></p><p>其要求的CPU其實已經佔用了t2.medium的1/20<br>每開一台新的node，其中最少1/20的CPU已經被系統佔用了<br>所以要做scaling的預算的話，當中的overhead也應計算在內</p><h3 id="Daemonset"><a href="#Daemonset" class="headerlink" title="Daemonset"></a>Daemonset</h3><p>如果你的系統有利用到daemonset的話<br>也會知道每個node都要跟據你的配置去跑一些服務<br>例如我在集群上跑的一些filebeat跟logrotate<br>這些東西都會在每個node新增之時”搶去”了一些CPU/內存等的資源</p><p>所以每台node新配置的時侯<br>一定的CPU/內存都會被佔用<br>而當你的服務器配置選擇比較低的話<br>其CPU/內存被佔用的比重就相對較高<br>簡單來說就是overhead比較大<br>因為一台t2.xlarge相比起四台t2.medium的話<br>其daemonset/預設服務的比重就直接少了3/4</p><p>而且實際情況很多時侯都是memory需求遠比cpu大<br>cpu需求高的服務我們更應該配置一台r系列的機器專門讓他跑</p><h2 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h2><p>那如果xlarge比medium好的話<br>2xlarge會否比xlarge更好？<br>我會說理論上是<br>但實際情況你需要分析：<br>你到底會跑多少個pod?<br>CPU/memory比重是多少？<br>多少daemon set在跑？<br>等等的問題<br>然後再選擇適合你的配置</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;公司的集群一直都在用t2.medium&lt;br&gt;原因是t2系列中可累積的CPU credit非常實用&lt;br&gt;詳情可參看 &lt;a href=&quot;/2018/09/19/aws-t2-medium/&quot; title=&quot;AWS中t2.medium的二三事&quot;&gt;AWS中t2.medium的二三事&lt;/a&gt;&lt;br&gt;而且medium的內存(4G)也夠跑一定數量的pod&lt;br&gt;比較比相當不錯&lt;/p&gt;
&lt;p&gt;但最近參考了其他人的做法&lt;br&gt;把node type從medium轉換成xlarge之後&lt;br&gt;node的數量大減之餘，價格亦有相當的減少&lt;br&gt;所以希望在此分享一下心得&lt;/p&gt;
&lt;h2 id=&quot;為什麼t2-xlarge會比t2-medium好&quot;&gt;&lt;a href=&quot;#為什麼t2-xlarge會比t2-medium好&quot; class=&quot;headerlink&quot; title=&quot;為什麼t2.xlarge會比t2.medium好&quot;&gt;&lt;/a&gt;為什麼t2.xlarge會比t2.medium好&lt;/h2&gt;&lt;p&gt;如果單看價錢的話&lt;br&gt;t2.xlarge的價錢是t2.medium的4倍&lt;br&gt;但只有2倍於medium(4個vCPU), cpu credit也沒有去到4倍&lt;br&gt;&lt;img src=&quot;/images/aws-pricing.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;這樣看的話只有內存才算是真的4倍&lt;br&gt;那為什麼說xlarge會比medium利用率更好呢？&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/tags/kubernetes/"/>
    
      <category term="aws" scheme="https://blog.nandiheath.com/tags/aws/"/>
    
  </entry>
  
  <entry>
    <title>把blog由wordpress轉移到hexo(下)</title>
    <link href="https://blog.nandiheath.com/2019/01/02/wordpress-migrate-hexo-2/"/>
    <id>https://blog.nandiheath.com/2019/01/02/wordpress-migrate-hexo-2/</id>
    <published>2019-01-02T09:35:55.000Z</published>
    <updated>2019-09-18T09:13:44.717Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hexo小心得"><a href="#Hexo小心得" class="headerlink" title="Hexo小心得"></a>Hexo小心得</h1><h2 id="從wordpress直接導入"><a href="#從wordpress直接導入" class="headerlink" title="從wordpress直接導入"></a>從wordpress直接導入</h2><p>安裝plugin</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save-dev hexo-migrator-wordpress</span><br></pre></td></tr></table></figure><p>注意這個plugin並不會把圖片自動下載<br>我是另外寫了一個script把圖片都下載並加入到項目當中<br>好一點當然是上傳到一些永久的空間(如cloudinary之類)</p><h2 id="SEO配置"><a href="#SEO配置" class="headerlink" title="SEO配置"></a>SEO配置</h2><p>加入sitemap及rss feed<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save-dev hexo-generator-feed</span><br><span class="line">npm install --save-dev hexo-generator-sitemap</span><br></pre></td></tr></table></figure></p><p>當然每個post你也應該設定一個好的slug及相關的tags</p><p>##　自訂theme</p><p>安裝hexo時就已經預載了一個theme於目錄<code>./themes/</code> 中<br>最簡單的方法就是直接修改<br>或者可以使用其他人所寫的theme</p><h2 id="摘要excerpt"><a href="#摘要excerpt" class="headerlink" title="摘要excerpt"></a>摘要excerpt</h2><p>在文章中加入以下script會自動生成文章摘要</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- more --&gt;</span><br></pre></td></tr></table></figure><h2 id="Facebook留言"><a href="#Facebook留言" class="headerlink" title="Facebook留言"></a>Facebook留言</h2><p>安裝plugin</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save-dev hexo-fbcomments</span><br></pre></td></tr></table></figure><p>修改<code>_config.yaml</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Enable facebook comments</span><br><span class="line">fbcomments:</span><br><span class="line">  enabled: true</span><br><span class="line">  lang: zh_HK</span><br><span class="line">  appId: [facebook_app_id]</span><br><span class="line">  numPosts: 20</span><br></pre></td></tr></table></figure><h2 id="發佈到github-pages"><a href="#發佈到github-pages" class="headerlink" title="發佈到github pages"></a>發佈到github pages</h2><p>先建立相應的github repo並新增一個orphan branch<br>可以看這裡 </p><p>然後安裝plugin</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save-dev hexo-deployer-git</span><br></pre></td></tr></table></figure><p>更改<code>_config.yaml</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Deployment</span><br><span class="line"># Docs: https://hexo.io/docs/deployment.html</span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: git@github.com:[username]/[reponame].git</span><br><span class="line">  branch: gh-pages</span><br><span class="line">  message:</span><br></pre></td></tr></table></figure><p>利用command發佈<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo generate --deploy</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hexo小心得&quot;&gt;&lt;a href=&quot;#Hexo小心得&quot; class=&quot;headerlink&quot; title=&quot;Hexo小心得&quot;&gt;&lt;/a&gt;Hexo小心得&lt;/h1&gt;&lt;h2 id=&quot;從wordpress直接導入&quot;&gt;&lt;a href=&quot;#從wordpress直接導入&quot; cla
      
    
    </summary>
    
      <category term="dev" scheme="https://blog.nandiheath.com/categories/dev/"/>
    
    
      <category term="github-pages" scheme="https://blog.nandiheath.com/tags/github-pages/"/>
    
      <category term="hexo" scheme="https://blog.nandiheath.com/tags/hexo/"/>
    
      <category term="blog" scheme="https://blog.nandiheath.com/tags/blog/"/>
    
      <category term="wordpress" scheme="https://blog.nandiheath.com/tags/wordpress/"/>
    
  </entry>
  
  <entry>
    <title>把blog由wordpress轉移到hexo(上)</title>
    <link href="https://blog.nandiheath.com/2019/01/02/wordpress-migrate-hexo/"/>
    <id>https://blog.nandiheath.com/2019/01/02/wordpress-migrate-hexo/</id>
    <published>2019-01-02T08:55:28.000Z</published>
    <updated>2019-09-18T09:13:44.718Z</updated>
    
    <content type="html"><![CDATA[<p>最近把這個blog由wordpress轉移到github pages上<br>同時亦利用了hexo來生成靜態網站<br>運行了一段時間後十分滿意<br>所以在此發表一下心得</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>Wordpress作為世界上最多人用的blog/cms系統<br>作為一個blog在功能上當然沒有任何不足<br>基本的SEO/CMS/Migrate功能已經有足夠的支持<br>但在我而言仍有部分不足之處</p><ul><li>缺乏版本控制</li><li>完整備份不算簡單(尤其是圖片)</li><li>需要數據庫</li><li>容易成為攻擊的目標</li></ul><p>因為我經常會把東西搬來搬去<br>e.g. 由自己家的服務器 &gt; Digital Ocean &gt; GKE &gt; GCP<br>每次需要搬blog的時侯就要找個plugin 把blog的內容導出再導入<br>還要擔心圖片沒搬遷成功 (有可能export出來的blog只把圖片導出成連結)<br>而且自己架的數據庫要定期做備份等等…</p><a id="more"></a><h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>說到Hexo不得不提一下static website<br>在互聯網初期很多人都是寫靜態網站<br>就是沒有數據庫<br>所有頁面都是一頁頁的html<br>非常簡單<br>最近也不知道是不是古老當時興<br>繼single page application之後static website也重新進入大眾的視線內<br>的確static website也是有其優點的</p><ul><li>最簡單的架構</li><li>無與倫比的速度</li></ul><p>雖然blog的話速度不需要考慮…</p><h2 id="Git-然後Github-pages"><a href="#Git-然後Github-pages" class="headerlink" title="Git, 然後Github pages"></a>Git, 然後Github pages</h2><p>或許你會問<br>static website generator架構簡單，是沒有數據庫<br>然後呢？我仍然要host要備份吧？</p><p>這個時侯就可以看一下Github pages了<br>github 有一個服務就是可以host一些簡單的靜態網頁<br>沒錯，結合hexo這類的靜態網頁生成器<br>無敵的組合就誕生了！</p><p>非常簡單的Stack:<br>一個git的hexo項目(可以是gitlab/github或者自己host)<br>一個github項目(用於發佈網站)<br>一個域名</p><p>一個不用擔心備份的Blog就這樣生成了！</p><a href="/2019/01/02/wordpress-migrate-hexo-2/" title="把blog由wordpress轉移到hexo(下)">把blog由wordpress轉移到hexo(下)</a><h2 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h2><ul><li><a href="https://pages.github.com/" target="_blank" rel="noopener">https://pages.github.com/</a></li><li><a href="https://hexo.io/" target="_blank" rel="noopener">https://hexo.io/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近把這個blog由wordpress轉移到github pages上&lt;br&gt;同時亦利用了hexo來生成靜態網站&lt;br&gt;運行了一段時間後十分滿意&lt;br&gt;所以在此發表一下心得&lt;/p&gt;
&lt;h2 id=&quot;原因&quot;&gt;&lt;a href=&quot;#原因&quot; class=&quot;headerlink&quot; title=&quot;原因&quot;&gt;&lt;/a&gt;原因&lt;/h2&gt;&lt;p&gt;Wordpress作為世界上最多人用的blog/cms系統&lt;br&gt;作為一個blog在功能上當然沒有任何不足&lt;br&gt;基本的SEO/CMS/Migrate功能已經有足夠的支持&lt;br&gt;但在我而言仍有部分不足之處&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缺乏版本控制&lt;/li&gt;
&lt;li&gt;完整備份不算簡單(尤其是圖片)&lt;/li&gt;
&lt;li&gt;需要數據庫&lt;/li&gt;
&lt;li&gt;容易成為攻擊的目標&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為我經常會把東西搬來搬去&lt;br&gt;e.g. 由自己家的服務器 &amp;gt; Digital Ocean &amp;gt; GKE &amp;gt; GCP&lt;br&gt;每次需要搬blog的時侯就要找個plugin 把blog的內容導出再導入&lt;br&gt;還要擔心圖片沒搬遷成功 (有可能export出來的blog只把圖片導出成連結)&lt;br&gt;而且自己架的數據庫要定期做備份等等…&lt;/p&gt;
    
    </summary>
    
      <category term="dev" scheme="https://blog.nandiheath.com/categories/dev/"/>
    
    
      <category term="github-pages" scheme="https://blog.nandiheath.com/tags/github-pages/"/>
    
      <category term="hexo" scheme="https://blog.nandiheath.com/tags/hexo/"/>
    
      <category term="blog" scheme="https://blog.nandiheath.com/tags/blog/"/>
    
      <category term="wordpress" scheme="https://blog.nandiheath.com/tags/wordpress/"/>
    
  </entry>
  
  <entry>
    <title>清除docker主機上的垃圾</title>
    <link href="https://blog.nandiheath.com/2018/12/13/docker-auto-cleanup/"/>
    <id>https://blog.nandiheath.com/2018/12/13/docker-auto-cleanup/</id>
    <published>2018-12-13T04:23:35.000Z</published>
    <updated>2019-09-18T09:13:44.710Z</updated>
    
    <content type="html"><![CDATA[<p>如果你在本機上有docker build，或者你的CI有用到docker build的時侯<br>每過一段時間就會發現佔用的空間會大得很誇張<br>原因是docker build的時侯會下載各種的base image，更甚者會建立各樣的fs layer<br>而且建立了的image/fs layer是不會主動去刪掉的<br>所以就需要設立一些cronjob 去定期把沒用/舊的東西刪掉去騰出更多的空間</p><a id="more"></a><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>linux的話只需要在<code>crontab</code>中設定<code>docker system prune</code>就可以了<br>這個指令會移除</p><ol><li>所有沒有被其他image引用的image (dangling images)</li><li>所有已停止的container</li><li>所有未被最少一個運行中的container使用的network</li><li>所有build cache</li></ol><p>如果想徹底一點的話可以使用<code>docker system prune -a</code><br>這個指令會把所有未用的image都刪掉<br>所以如果一些image 有引用到其他image時，當你再build的時侯就需要重新下載了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">0 0 * * * /usr/bin/docker system prune -f</span><br></pre></td></tr></table></figure><p>這樣每天零晨零時(UTC，詳細請檢查服務器設定)就會運行system prune了<br>但因為這個動作第一次運行時會需時很久，所以千萬請挑選服務器空閒的時間才執行</p><h3 id="執行system-prune時當機"><a href="#執行system-prune時當機" class="headerlink" title="執行system prune時當機"></a>執行system prune時當機</h3><p>有時侯運行image prune 時會導致docker 整個掛掉，需要重啟一下docker才能再次執行ps/info等命令<br>所以可以利用其他命令先把image的數量減少一下<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker rmi $(docker images --filter <span class="string">"dangling=true"</span> -q --no-trunc)</span><br></pre></td></tr></table></figure></p><p><a href="https://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images" target="_blank" rel="noopener">https://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images</a></p><h2 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h2><ul><li><a href="https://nickjanetakis.com/blog/docker-tip-32-automatically-clean-up-after-docker-daily" target="_blank" rel="noopener">https://nickjanetakis.com/blog/docker-tip-32-automatically-clean-up-after-docker-daily</a></li><li><a href="https://docs.docker.com/engine/reference/commandline/system_prune/#examples" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/commandline/system_prune/#examples</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果你在本機上有docker build，或者你的CI有用到docker build的時侯&lt;br&gt;每過一段時間就會發現佔用的空間會大得很誇張&lt;br&gt;原因是docker build的時侯會下載各種的base image，更甚者會建立各樣的fs layer&lt;br&gt;而且建立了的image/fs layer是不會主動去刪掉的&lt;br&gt;所以就需要設立一些cronjob 去定期把沒用/舊的東西刪掉去騰出更多的空間&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
    
      <category term="docker" scheme="https://blog.nandiheath.com/tags/docker/"/>
    
      <category term="system" scheme="https://blog.nandiheath.com/tags/system/"/>
    
      <category term="prune" scheme="https://blog.nandiheath.com/tags/prune/"/>
    
      <category term="build" scheme="https://blog.nandiheath.com/tags/build/"/>
    
  </entry>
  
  <entry>
    <title>當elasticsearch硬碟滿了</title>
    <link href="https://blog.nandiheath.com/2018/11/02/elasticsearch-disk-full/"/>
    <id>https://blog.nandiheath.com/2018/11/02/elasticsearch-disk-full/</id>
    <published>2018-11-02T08:51:17.000Z</published>
    <updated>2019-09-18T09:13:44.713Z</updated>
    
    <content type="html"><![CDATA[<p>不小心把dev場gRPC的debug log打開了，導致每天產生了差不多800萬條event<br>把本來就剩不了多少的空間直接塞爆了，碰巧prometheus跟logstash在同一個節點上<br>prometheus不幸地掛掉了導致連訊息也沒收到<br>過了兩三天才發覺數據沒了才發現出事</p><p>最後要搞了兩天才把數據回復<br>幸運的是開始時就已經設置了一些機制去防錯<br>因此這次才沒有發展成為災難性的事件<br>就寫了以下的一些分享</p><a id="more"></a><hr><h3 id="1-log-shipper很重要"><a href="#1-log-shipper很重要" class="headerlink" title="1. log shipper很重要"></a>1. log shipper很重要</h3><p>在一開始使用ELK stack時也有考慮過經TCP直接由logger經TCP直接傳給logstash/es<br>但考慮到多個因素如網絡/服務器穩定性等就決定用filebeat<br>filebeat的好處是你直接把日誌打到file裡去，然後再加一個logrotate去設定輪替<br><strong>這點很重要，不然日誌的檔案只會增不會減，儲存空間會變成另一個問題</strong><br>然後經filebeat上傳到logstash/es</p><p>如果你使用network logging的話<br>只要logstash/es 報錯，那麼你那段時間的log就真的變沒有了(除非你會重寫，但也因此有更多的東西要兼顧)<br>而用filebeat的話你還有一段時間可以排錯修復(logrotate 一般就7-10日)<br>這正正給了我時間去把那些沒有上傳的log 重新上載…</p><h3 id="2-non-prod的log最好用curator每日清掉"><a href="#2-non-prod的log最好用curator每日清掉" class="headerlink" title="2. non-prod的log最好用curator每日清掉"></a>2. non-prod的log最好用curator每日清掉</h3><p>若非要測試，那麼非production場的數據應該要及早刪掉<br>不然index數量只會越來越多…</p><h3 id="3-match-timestamp是很重要的"><a href="#3-match-timestamp是很重要的" class="headerlink" title="3. match timestamp是很重要的"></a>3. match timestamp是很重要的</h3><p>ES本身的設定是你什麼時侯上傳event給他，他就會預設把該event的時間設定為該時間<br>可以透過logstash把log裡面的時間覆蓋掉本來的timestamp<br>這個好處是event在es的timestamp變得更有意義(由上傳時間變為發生時間)<br>更大的好處是如果你高負載/重新上傳時時間資訊就不會丟失</p><h3 id="4-ES本身的硬碟防爆機制"><a href="#4-ES本身的硬碟防爆機制" class="headerlink" title="4. ES本身的硬碟防爆機制"></a>4. ES本身的硬碟防爆機制</h3><p>詳細可看這裡<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.x/disk-allocator.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.x/disk-allocator.html</a><br>簡單來說就是ES會把硬碟快滿分別三個階段</p><p><code>cluster.routing.allocation.disk.watermark.low</code></p><ul><li>預設85% 當某個節點超過這個限額後ES會停止分配shards到其之上</li></ul><p><code>cluster.routing.allocation.disk.watermark.high</code></p><ul><li>預設90% 當某個節點超過這個限額後ES會嘗試把該節點的shards分配到其他節點上</li></ul><p><code>cluster.routing.allocation.disk.watermark.flood_stage</code></p><ul><li><p>預設95% 當某個節點超過這個限額後ES會把該節點的所有index都加一個flag <code>index.blocks.read_only_allow_delete</code></p><p>意味著那些index變成唯讀，防止硬碟真的爆滿</p></li></ul><hr><p>最後回復數據時卡最久就是<code>index.blocks.read_only_allow_delete</code>這個機制<br>因為當我把兩個data node的硬碟空間都增加了之後<br>logstash/filebeat都卡住不動，es也沒有看到有新數據進來<br>搞了很久才發現這個機制</p><p>而要解決也很解單的，只需要更新每個index的設定，把這枝flag設成null就可以了<br>(當然最好就是逐個index去解鎖)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reset all the read only flag for all indices</span></span><br><span class="line">PUT /_all/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"index.blocks.read\_only\_allow_delete"</span>: null</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不小心把dev場gRPC的debug log打開了，導致每天產生了差不多800萬條event&lt;br&gt;把本來就剩不了多少的空間直接塞爆了，碰巧prometheus跟logstash在同一個節點上&lt;br&gt;prometheus不幸地掛掉了導致連訊息也沒收到&lt;br&gt;過了兩三天才發覺數據沒了才發現出事&lt;/p&gt;
&lt;p&gt;最後要搞了兩天才把數據回復&lt;br&gt;幸運的是開始時就已經設置了一些機制去防錯&lt;br&gt;因此這次才沒有發展成為災難性的事件&lt;br&gt;就寫了以下的一些分享&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="aws" scheme="https://blog.nandiheath.com/tags/aws/"/>
    
      <category term="elasticsearch" scheme="https://blog.nandiheath.com/tags/elasticsearch/"/>
    
      <category term="elk" scheme="https://blog.nandiheath.com/tags/elk/"/>
    
      <category term="filebeat" scheme="https://blog.nandiheath.com/tags/filebeat/"/>
    
      <category term="k8s" scheme="https://blog.nandiheath.com/tags/k8s/"/>
    
      <category term="logstash" scheme="https://blog.nandiheath.com/tags/logstash/"/>
    
  </entry>
  
  <entry>
    <title>利用不同的private key去存取git</title>
    <link href="https://blog.nandiheath.com/2018/10/04/different-private-key-for-git/"/>
    <id>https://blog.nandiheath.com/2018/10/04/different-private-key-for-git/</id>
    <published>2018-10-04T05:25:06.000Z</published>
    <updated>2019-09-18T09:13:44.710Z</updated>
    
    <content type="html"><![CDATA[<p>如果同一台電腦需要存取不同的git項目，但由於身份的不同你會有多過一個private key<br>SSH時很簡單的用 -i 就可以了<br>但git就稍為複雜  </p><a id="more"></a><h2 id="方法一-利用environment-variable去指定SSH用的private-key"><a href="#方法一-利用environment-variable去指定SSH用的private-key" class="headerlink" title="方法一: 利用environment variable去指定SSH用的private key"></a>方法一: 利用environment variable去指定SSH用的private key</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">GIT_SSH_COMMAND=<span class="string">"ssh -i ~/.ssh/id_rsa_example"</span> git <span class="built_in">clone</span> example.com/repo.git</span><br></pre></td></tr></table></figure><h2 id="方法二-推薦-利用ssh-config"><a href="#方法二-推薦-利用ssh-config" class="headerlink" title="方法二(推薦): 利用ssh config"></a>方法二(推薦): 利用ssh config</h2><p>首先你需要新增一個檔案</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># permission需為600</span></span><br><span class="line">touch ~/.ssh/config</span><br></pre></td></tr></table></figure><p>這個檔案讓你的SSH知道不同的host name對應的設置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Company Account</span></span><br><span class="line">host gitlab.com-company</span><br><span class="line">        HostName gitlab.com</span><br><span class="line">        User git</span><br><span class="line">        IdentityFile ~/.ssh/my_company_id_rsa</span><br><span class="line"></span><br><span class="line"><span class="comment"># Personal Account</span></span><br><span class="line">host gitlab.com-personal</span><br><span class="line">        HostName gitlab.com</span><br><span class="line">        User git</span><br><span class="line">        IdentityFile ~/.ssh/my_personal_id_rsa</span><br></pre></td></tr></table></figure><p>之後就可以直接用不同的private key去存取不同的repo了<br>但要注意是這邊用到的是你剛剛設定的<code>gitlab.com-company</code>,而不是<code>gitlab.com</code><br>否則只會用默認的private key(如~/.ssh/id_rsa)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 實例</span></span><br><span class="line"><span class="comment"># 存取公司repo</span></span><br><span class="line">git <span class="built_in">clone</span> git@gitlab.com-company:company-repo/a-project.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存取私人repo</span></span><br><span class="line">git <span class="built_in">clone</span> git@gitlab.com-personal:my-repo/another-project.git</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果同一台電腦需要存取不同的git項目，但由於身份的不同你會有多過一個private key&lt;br&gt;SSH時很簡單的用 -i 就可以了&lt;br&gt;但git就稍為複雜  &lt;/p&gt;
    
    </summary>
    
      <category term="dev" scheme="https://blog.nandiheath.com/categories/dev/"/>
    
    
      <category term="git" scheme="https://blog.nandiheath.com/tags/git/"/>
    
      <category term="key" scheme="https://blog.nandiheath.com/tags/key/"/>
    
      <category term="ssh" scheme="https://blog.nandiheath.com/tags/ssh/"/>
    
  </entry>
  
  <entry>
    <title>ES6 destructuring 參數</title>
    <link href="https://blog.nandiheath.com/2018/10/02/es6-destructuring/"/>
    <id>https://blog.nandiheath.com/2018/10/02/es6-destructuring/</id>
    <published>2018-10-02T10:54:43.000Z</published>
    <updated>2019-09-18T09:13:44.713Z</updated>
    
    <content type="html"><![CDATA[<p>Destructuring (解構賦值)是es6中很常用的語法<br>用處是不用點(.)來點(.)去，直接把Object中的值化為實際變量來使用</p><hr><p>簡單的例子</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> somdata = &#123;</span><br><span class="line">  id: <span class="string">"1"</span>,</span><br><span class="line">  user_name: <span class="string">"Nandi"</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 舊式寫法</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> user\_name = data.user\_name;</span><br><span class="line"><span class="keyword">var</span> id = data.id;</span><br><span class="line"></span><br><span class="line">updateUsername(id, user_name);</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 利用 destructuring</span></span><br><span class="line"><span class="keyword">const</span> &#123;</span><br><span class="line">  id,</span><br><span class="line">  user_name  </span><br><span class="line">&#125; = data;</span><br><span class="line"></span><br><span class="line">updateUsername(id, user_name);</span><br></pre></td></tr></table></figure><a id="more"></a><p>有時侯function中的參數也會用到destructuring</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// without destructuring</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">someFunc</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> param1 = data.param1;</span><br><span class="line">  <span class="keyword">const</span> param2 = data.param2;</span><br><span class="line">  <span class="keyword">const</span> param3 = data.param3;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// with destructuring</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">someFunc</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">  param1,</span></span></span><br><span class="line"><span class="function"><span class="params">  param2,</span></span></span><br><span class="line"><span class="function"><span class="params">  param3</span></span></span><br><span class="line"><span class="function"><span class="params">&#125;</span>) </span>&#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>這個寫法有一個好處<br>因為原本的寫法在method的參數當中你只知道傳進了data但卻沒有說明data的格式為何</p><p>利用Destructuring則可以把data的格式更清楚地列明，有效減少代碼的錯誤，亦提高了代碼的可讀性<br>但當destructring 配合default parameters來使用時就需要小心了</p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">printParam</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">  param1 = <span class="string">"default_value1"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  param2 = <span class="string">"default_value2"</span></span></span></span><br><span class="line"><span class="function"><span class="params">&#125;</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(param1);</span><br><span class="line">  <span class="built_in">console</span>.log(param2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 傳空的object進去沒問題</span></span><br><span class="line">printParam(&#123;&#125;)</span><br><span class="line">&gt; default_value1</span><br><span class="line">&gt; default_value2</span><br><span class="line"></span><br><span class="line"><span class="comment">// 傳其中一個參數也沒問題</span></span><br><span class="line">printParam(&#123; <span class="attr">param1</span>: <span class="string">'somedata'</span> &#125;)</span><br><span class="line">&gt; somedata</span><br><span class="line">&gt; default_value2</span><br><span class="line"></span><br><span class="line"><span class="comment">// 這樣就出問題了</span></span><br><span class="line">printParam();</span><br><span class="line">&gt; <span class="built_in">TypeError</span>: Cannot destructure property <span class="string">`varA`</span> <span class="keyword">of</span> <span class="string">'undefined'</span> or <span class="string">'null'</span>.</span><br></pre></td></tr></table></figure><p>原因是printParam中的default param是建基於你傳進去的object，而並不是之外的param<br>所以這樣寫的時侯需要加倍小心</p><p>正確的寫法應該是這樣  </p><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//　正確寫法</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">printParam</span>(<span class="params">&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">  param1 = <span class="string">"default_value1"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  param2 = <span class="string">"default_value2"</span></span></span></span><br><span class="line"><span class="function"><span class="params">&#125; = &#123;&#125; </span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(param1);</span><br><span class="line">  <span class="built_in">console</span>.log(param2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&gt; default_value1</span><br><span class="line">&gt; default_value2</span><br></pre></td></tr></table></figure><p>這樣寫就會把本身要傳進去的object參數也建立一個預設值，當你什麼都沒傳進去時就會生成一個空的object<br>然後再把本身object中的參數按預設值再生成</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Destructuring (解構賦值)是es6中很常用的語法&lt;br&gt;用處是不用點(.)來點(.)去，直接把Object中的值化為實際變量來使用&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;簡單的例子&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; somdata = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  id: &lt;span class=&quot;string&quot;&gt;&quot;1&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  user_name: &lt;span class=&quot;string&quot;&gt;&quot;Nandi&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 舊式寫法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; user\_name = data.user\_name;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; id = data.id;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;updateUsername(id, user_name);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 利用 destructuring&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  id,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  user_name  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125; = data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;updateUsername(id, user_name);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="dev" scheme="https://blog.nandiheath.com/categories/dev/"/>
    
    
      <category term="nodejs" scheme="https://blog.nandiheath.com/tags/nodejs/"/>
    
      <category term="javascript" scheme="https://blog.nandiheath.com/tags/javascript/"/>
    
      <category term="es6" scheme="https://blog.nandiheath.com/tags/es6/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes中清空一個node的所有pod</title>
    <link href="https://blog.nandiheath.com/2018/09/19/k8s-drain-pod-inside-node/"/>
    <id>https://blog.nandiheath.com/2018/09/19/k8s-drain-pod-inside-node/</id>
    <published>2018-09-19T11:16:26.000Z</published>
    <updated>2019-09-18T09:13:44.714Z</updated>
    
    <content type="html"><![CDATA[<p>有時侯kubernetes中有些node會出現故障 這時侯就需要用到兩個命令 drain及uncordon</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先獲取node 的名字</span></span><br><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令node開始釋放所有pod, 並且不接收新的pod 排程</span></span><br><span class="line">kubectl drain [node-name] --force --ignore-daemonsets --delete-local-data</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 這時侯把該做的事情都做一下 ...</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢復node，回復接收新的pod 排程</span></span><br><span class="line">kubectl uncordon [node-name]</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="drain的參數"><a href="#drain的參數" class="headerlink" title="drain的參數"></a>drain的參數</h3><p><code>--force</code><br>當一些pod不是經 ReplicationController, ReplicaSet, Job, DaemonSet 或者 StatefulSet 管理時<br>就需要用<code>--force</code>來強制執行 (例如:<strong>kube-proxy</strong>)</p><p><code>--ignore-daemonsets</code><br>無視DaemonSet管理下的Pod</p><p><code>--delete-local-data</code><br>如果有mount local volumn的pod，會強制殺掉該pod並把資料清除掉<br>另外如果跟本身的配置訊息有衝突時，drain就不會執行</p><p>例如你在一個運行了三個replica的statefulSet中設定了PodDisruptionBudget，而minAvaliability又設成了2，當正在運行的pod數量等於或少於2的時侯，drain就會停止執行</p><hr><h4 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h4><ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有時侯kubernetes中有些node會出現故障 這時侯就需要用到兩個命令 drain及uncordon&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 先獲取node 的名字&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl get nodes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 命令node開始釋放所有pod, 並且不接收新的pod 排程&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl drain [node-name] --force --ignore-daemonsets --delete-local-data&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 這時侯把該做的事情都做一下 ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 恢復node，回復接收新的pod 排程&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubectl uncordon [node-name]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/tags/kubernetes/"/>
    
      <category term="drain" scheme="https://blog.nandiheath.com/tags/drain/"/>
    
      <category term="kubectl" scheme="https://blog.nandiheath.com/tags/kubectl/"/>
    
  </entry>
  
  <entry>
    <title>AWS中t2.medium的二三事</title>
    <link href="https://blog.nandiheath.com/2018/09/19/aws-t2-medium/"/>
    <id>https://blog.nandiheath.com/2018/09/19/aws-t2-medium/</id>
    <published>2018-09-19T07:45:44.000Z</published>
    <updated>2019-09-18T09:13:44.706Z</updated>
    
    <content type="html"><![CDATA[<h2 id="t2系列的優點"><a href="#t2系列的優點" class="headerlink" title="t2系列的優點"></a>t2系列的優點</h2><h3 id="CPU是按用量算的"><a href="#CPU是按用量算的" class="headerlink" title="CPU是按用量算的"></a>CPU是按用量算的</h3><p>平時用剩的可以累積，當然是有上限啦<br>到需要爆發的時侯把儲起來的credit消費掉(?)<br>好處是你一些難以估算用量的service你可以放心的跑起來</p><h3 id="性價比高"><a href="#性價比高" class="headerlink" title="性價比高"></a>性價比高</h3><p>跟同樣配置的c4.large (2vCPU, 4GB Ram)<br>比起來便宜一半有多($33.97 vs $73.20)</p><a id="more"></a><hr><p>所以我在kubernetes當中用的機器大部份都是t2.medium<br>雖然大部份的情況下都活得很好<br>但也有發生意外的時侯<br>那就是<strong>CPU credit不夠</strong></p><p>這裡要先說明一下t2系列的機制<br>t2系列的CPU用量跟其他的不同<br>AWS會為每個機器每個小時發一定量的CPU Credit<br>然後扣取你該小時的用量(1 credit = 100% CPU 運行一分鐘)<br>而不同的instance type可以儲存的credit 也有上限<br><img src="/images/aws-t2-medium-1.png" alt=""></p><p>如果你連續200%CPU跑了好長的一段時間，你的cpu credit很快就會變成0<br>而這個時侯機器上所有的進程基本上都會卡住不動<br>等到有CPU credit回復時才跑一點點<br>簡單來說就是卡死了</p><p>所以如果要拿t2系列的機器來做kubernetes的node的話<br>有幾樣事情是必需的</p><h2 id="有效利用t2"><a href="#有效利用t2" class="headerlink" title="有效利用t2　"></a>有效利用t2　</h2><h3 id="CPU-credit-監控"><a href="#CPU-credit-監控" class="headerlink" title="CPU credit 監控"></a>CPU credit 監控</h3><p>Prometheus 可以安裝一個插件去監控AWS的E2 CPU Credit<br><img src="/images/aws-t2-medium-2.png" alt=""><br>於CPU credit用量異常或者是不夠的時便發通知(我是利用telegram)<br>當然你也可以用AWS的cloudwatch直接監控及發通知，原理上是一樣的</p><h3 id="合適的資源配置"><a href="#合適的資源配置" class="headerlink" title="合適的資源配置"></a>合適的資源配置</h3><p>在設計每個服務時應該先考慮到實時的同量<br>不然kubernetes在分配資源的時侯很有可能把一堆消耗CPU/內存的大戶放在同一node上</p><p>當然在初期很難作出有效的估算，所以我建議初期應該花更多的時間去做監控<br>密切留意每個服務的資源需求，以便有效作出調整<br>當發現部份服務的資源需求過高，你就需要作出決定<br>一是把他的resource request調高，把其他服務擠走<br>又或者專門配置一些node給他們單獨跑</p><p>最後吐槽一下<br>gcloud沒有類似的brustable instance，差評</p><h2 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h2><ul><li><a href="/2018/02/22/grafana-prometheus/" title="利用Prometheus去監控AWS EC2的CPU credit">利用Prometheus去監控AWS EC2的CPU credit</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;t2系列的優點&quot;&gt;&lt;a href=&quot;#t2系列的優點&quot; class=&quot;headerlink&quot; title=&quot;t2系列的優點&quot;&gt;&lt;/a&gt;t2系列的優點&lt;/h2&gt;&lt;h3 id=&quot;CPU是按用量算的&quot;&gt;&lt;a href=&quot;#CPU是按用量算的&quot; class=&quot;headerlink&quot; title=&quot;CPU是按用量算的&quot;&gt;&lt;/a&gt;CPU是按用量算的&lt;/h3&gt;&lt;p&gt;平時用剩的可以累積，當然是有上限啦&lt;br&gt;到需要爆發的時侯把儲起來的credit消費掉(?)&lt;br&gt;好處是你一些難以估算用量的service你可以放心的跑起來&lt;/p&gt;
&lt;h3 id=&quot;性價比高&quot;&gt;&lt;a href=&quot;#性價比高&quot; class=&quot;headerlink&quot; title=&quot;性價比高&quot;&gt;&lt;/a&gt;性價比高&lt;/h3&gt;&lt;p&gt;跟同樣配置的c4.large (2vCPU, 4GB Ram)&lt;br&gt;比起來便宜一半有多($33.97 vs $73.20)&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/tags/kubernetes/"/>
    
      <category term="aws" scheme="https://blog.nandiheath.com/tags/aws/"/>
    
      <category term="prometheus" scheme="https://blog.nandiheath.com/tags/prometheus/"/>
    
      <category term="t2.medium" scheme="https://blog.nandiheath.com/tags/t2-medium/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch Cluster出事了</title>
    <link href="https://blog.nandiheath.com/2018/09/19/elasticsearch-cluster-oom/"/>
    <id>https://blog.nandiheath.com/2018/09/19/elasticsearch-cluster-oom/</id>
    <published>2018-09-19T03:33:30.000Z</published>
    <updated>2019-09-18T09:13:44.712Z</updated>
    
    <content type="html"><![CDATA[<p>最近一次在kibana上的跨index搜索後<br>elasticsearch其中一個node就不斷重啟<br>而每次reshard的時間也越來越長<br><img src="/images/elasticsearch-cluster-oom-0.png" alt=""></p><p>最後發現問題原來出自kubernetes上<br>放es的節點上忘記把他taint了<br>結果其他POD也分配到上面運行<br>結果就造成了一個惡性循環<br>內存佔用太多導致OOM &gt; POD重啟 &gt;　ES節點重新加入到ES cluster &gt; 重新分配shard &gt; 內存佔用太多導致OOM  </p><p>雖然說是k8s的設定不當<br>但es上的確也有些設定問題需要改善</p><a id="more"></a><hr><h3 id="1-shard數量太多"><a href="#1-shard數量太多" class="headerlink" title="1. shard數量太多"></a>1. shard數量太多</h3><p>首先由於這個ES是用來分析日誌，不同的service的index也不同，而index採用的是[env]-[service]-[YYYY-MM-DD]這個方式，結果每日產生的index數量就是大概 5 x 3 x 2(3個環境 dev/stag/prod，5個服務，每個index兩個shard)</p><h4 id="解決方案"><a href="#解決方案" class="headerlink" title="解決方案"></a>解決方案</h4><p>會用curator刪掉的index才用YYYY-MM-DD,　其他的用YYYY-MM就可以了，因為通常只查詢兩個月內的數據<br>而採用YYYY-MM的應該設定成shard: 5, replica: 1，方便負戴管理<br>也可以利用/index/close的指令來把很少用的index關掉，雖然說會額外增的硬碟容量… <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-open-close.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-open-close.html</a></p><h3 id="2-master-data-node-負載不均"><a href="#2-master-data-node-負載不均" class="headerlink" title="2. master/data node 負載不均"></a>2. master/data node 負載不均</h3><p>因為省錢的關係只開了兩台AWS R4的node,，各自有一個master + data node<br>低負載環境下沒問題，但每當reschedule的時侯CPU就會衝到很高了</p><h4 id="解決方案-1"><a href="#解決方案-1" class="headerlink" title="解決方案"></a>解決方案</h4><p>多配兩台機來跑master<br>雖然文檔說master需求不大，但”不大”也只是相對起data node來說…</p><h3 id="3-replica設定不當"><a href="#3-replica設定不當" class="headerlink" title="3. replica設定不當"></a>3. replica設定不當</h3><p><code>shard:1 replica:1</code>在只有兩個data node的時侯是相當雞肋的<br>而且這邊我也不肯定到底是不是hard affinity<br>有時重reschedule的時便總發現有少部份( ~50/20000)的unassigned_shards</p><h4 id="解決方案-2"><a href="#解決方案-2" class="headerlink" title="解決方案"></a>解決方案</h4><p>最少配置３台data node<br>而且用原本的配置<code>shard:5 replica:1</code><br>但前提index的數量要少但容量要大<br>log型式的index還是用回<code>shard:1 replica:1</code>的配置</p><h3 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h3><p>elastic search裡面有很多很多設定<br>一開始的時侯資料量不大，不會引起太大問題<br>但當數量增加到某個量級的時侯就會開始造成一堆問題<br>理想當然是在開始設計架構的時侯就已經考慮到每種<code>index</code>的應用狀況<br>從而設定好<code>shard</code>/<code>replica</code>等的數量<br>否則上線之後才更改<code>index</code>或相關的設定可是相當危險的…</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近一次在kibana上的跨index搜索後&lt;br&gt;elasticsearch其中一個node就不斷重啟&lt;br&gt;而每次reshard的時間也越來越長&lt;br&gt;&lt;img src=&quot;/images/elasticsearch-cluster-oom-0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;最後發現問題原來出自kubernetes上&lt;br&gt;放es的節點上忘記把他taint了&lt;br&gt;結果其他POD也分配到上面運行&lt;br&gt;結果就造成了一個惡性循環&lt;br&gt;內存佔用太多導致OOM &amp;gt; POD重啟 &amp;gt;　ES節點重新加入到ES cluster &amp;gt; 重新分配shard &amp;gt; 內存佔用太多導致OOM  &lt;/p&gt;
&lt;p&gt;雖然說是k8s的設定不當&lt;br&gt;但es上的確也有些設定問題需要改善&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="elasticsearch" scheme="https://blog.nandiheath.com/tags/elasticsearch/"/>
    
      <category term="kubenetes" scheme="https://blog.nandiheath.com/tags/kubenetes/"/>
    
      <category term="taint" scheme="https://blog.nandiheath.com/tags/taint/"/>
    
  </entry>
  
  <entry>
    <title>[轉載]寫給工程師的十條精進原則</title>
    <link href="https://blog.nandiheath.com/2018/08/23/ten-principles-for-software-engineers/"/>
    <id>https://blog.nandiheath.com/2018/08/23/ten-principles-for-software-engineers/</id>
    <published>2018-08-23T09:34:25.000Z</published>
    <updated>2019-09-18T09:13:44.717Z</updated>
    
    <content type="html"><![CDATA[<p>最近看到美團的技術團隊所寫的一篇文章有感，特此分享<br>傳送門: <a href="https://tech.meituan.com/10_principles_for_engineers.html" target="_blank" rel="noopener">https://tech.meituan.com/10_principles_for_engineers.html</a><br>裡面提到有幾點也是現在我的團隊所缺乏的，藉此也可好好檢視下自己的不足  </p><h2 id="以终为始"><a href="#以终为始" class="headerlink" title="以终为始"></a>以终为始</h2><blockquote><p>“以终为始”（Begin With The End In Mind），是史蒂芬·柯维在《高效能人士的七个习惯》中提到的一个习惯。它是以所有事物都经过两次创造的原则（第一次为心智上的创造，第二次为实际的创造）为基础的。直观的表达就是：<strong>先想清楚目标，然后努力实现。</strong></p></blockquote><p>很多時侯工程師的壞習慣就是想到就動手做，但沒規劃好做出來的其實跟需求相去甚遠<br>先想清楚，制定好一個能量化的目標<br>然後以該目標為前題把需要的步驟詳列出來<br>為做而做並不會為項目帶來什麼</p><a id="more"></a><h2 id="闭环思维"><a href="#闭环思维" class="headerlink" title="闭环思维"></a>闭环思维</h2><blockquote><p><strong>真正的闭环，要求我们对工作中的事情都能够养成良好的思维习惯，沟通要有结论，通知要有反馈，To Do要有验收。</strong></p></blockquote><p>跟一直以來提倡的TDD很相似，現實卻是時間不容許<br>很多時侯跟別人討論一大輪結果卻不了了之，這個時侯就應該由Owner主導，訂下相關的目標及驗收準則<br>好讓一件事有一個『閉環』，這就跟scrum的workflow類似<br><code>PENDING&gt;IN PROGRESS&gt;WAITING FOR REVIEW&gt; CLOSE</code><br>永遠需要一個CLOSE，否則issue只會無限的累積下去</p><h2 id="事不过二"><a href="#事不过二" class="headerlink" title="事不过二"></a>事不过二</h2><blockquote><p>  一层含义是<strong>“所有的评审与问题讨论，不要超过两次”</strong>。 …… “事不过二”原则的另一层含义，是<strong>“同样的错误不能犯第二次”</strong>。每次故障之后，Casestudy都必须进行深刻的总结复盘，对故障原因进行5Why分析，给出明确可执行的To Do List。</p></blockquote><p>事不過二是一個重要的思維，無論是討論還是除錯。工作上無數次出現過就同一事情發生N次的討論，最後也沒有結論。問題重心其一是缺乏Owner主導，沒有明確的討論方向，很多時侯討論到流於表面，或只就眼前發生的事情討論，沒有定論也就不能閉環；其二是缺乏文檔，導致之後會忘記以前所討論的內容。 解決方案是加入Owner思維，及每次討論都需要有一個明確的TODO，並需要把結論寫進文檔   而除錯亦是另一個問題所在。每當有BUG出現時，大多都沒有詳細把該問題分級，而是選擇立即去解決，事後也沒有詳細的記錄相關的步驟。而之後同樣的問題再次出現時，就是憑經驗去解決，但很多時侯都會重新思考一些曾經經過的步驟，做成浪費。 解決方案當然是把除錯步驟寫進文檔，但亦需要拿捏當中的程度，考慮什麼類型的BUG才需要詳列其步驟。  </p><h2 id="设计优先"><a href="#设计优先" class="headerlink" title="设计优先"></a>设计优先</h2><blockquote><p>“设计优先”这条原则，相对来说更加具体一些。之所以单列一项，是因为架构设计太重要了。Uncle Bob曾说过：“软件架构的目标，是为了让构建与维护系统的所需人力资源最小化。” <strong>……</strong> <strong>“设计优先”这一原则，要求写别人看得懂的设计</strong>。我们了解一个系统最直接的途径就是结合设计文档与代码。</p></blockquote><p>MD&gt;5就需要文檔，絕對同意  </p><h2 id="空杯心态"><a href="#空杯心态" class="headerlink" title="空杯心态"></a>空杯心态</h2><blockquote><p>“满招损，谦受益”，“空杯心态”是最后一项原则。我觉得这也是一个人能够持续成长的前提。做技术的人，骨子里通常有股傲气，并且会随着资历、成绩的提升而不断增加。</p></blockquote><p>常言道：學而後知不足<br>你懂的再多，但每個人也肯定會懂一些你不懂的事<br>擺正心態，你需要的是進步，而不是自滿<br></p><p>以上，共勉之</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看到美團的技術團隊所寫的一篇文章有感，特此分享&lt;br&gt;傳送門: &lt;a href=&quot;https://tech.meituan.com/10_principles_for_engineers.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://tech.meituan.com/10_principles_for_engineers.html&lt;/a&gt;&lt;br&gt;裡面提到有幾點也是現在我的團隊所缺乏的，藉此也可好好檢視下自己的不足  &lt;/p&gt;
&lt;h2 id=&quot;以终为始&quot;&gt;&lt;a href=&quot;#以终为始&quot; class=&quot;headerlink&quot; title=&quot;以终为始&quot;&gt;&lt;/a&gt;以终为始&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;“以终为始”（Begin With The End In Mind），是史蒂芬·柯维在《高效能人士的七个习惯》中提到的一个习惯。它是以所有事物都经过两次创造的原则（第一次为心智上的创造，第二次为实际的创造）为基础的。直观的表达就是：&lt;strong&gt;先想清楚目标，然后努力实现。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很多時侯工程師的壞習慣就是想到就動手做，但沒規劃好做出來的其實跟需求相去甚遠&lt;br&gt;先想清楚，制定好一個能量化的目標&lt;br&gt;然後以該目標為前題把需要的步驟詳列出來&lt;br&gt;為做而做並不會為項目帶來什麼&lt;/p&gt;
    
    </summary>
    
      <category term="dev" scheme="https://blog.nandiheath.com/categories/dev/"/>
    
    
      <category term="software-engineering" scheme="https://blog.nandiheath.com/tags/software-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus中監控AWS EC2的CPU credit</title>
    <link href="https://blog.nandiheath.com/2018/08/14/ec2-cpu-credit-monitoring-in-prometheus/"/>
    <id>https://blog.nandiheath.com/2018/08/14/ec2-cpu-credit-monitoring-in-prometheus/</id>
    <published>2018-08-14T07:59:19.000Z</published>
    <updated>2019-09-18T09:13:44.711Z</updated>
    
    <content type="html"><![CDATA[<p>公司用的kubernetes nodes大部份都是t2 type<br>好處是便宜、彈性大，但壞處也相當明顯<br>當CPU使用率比CPU credit回復的速度慢時，有機會導致cpu credit變成0(或者相當接近0)<br>導致該節點的CPU效能降到極低，大部份進程都會卡住甚至當機<br>這個情況已經發生過不只一次<br>例如在某個node上的rabbitmq(對，沒有用到dedicated 的node)<br>因為有個chromium的pod在同一機器上跑，而且他是以cron job形式去跑，再加上有該死bug，亦沒有設定retry count<br>結果就是山積了一堆job在同一個node上不停跑<br>過了幾天整個CPU credit變成0，rabbitmq掛掉<br>很多其他pod也因此卡死(或者不斷重啟)</p><a id="more"></a><hr><p>現在加了prometheus的cloudwatch plugin<br>當cpu credit使用率過高時會直接經telegram通知我，問題就解決了！(希望)</p><p>要注意的是cloudwatch API是需要<strong>付費</strong>的<br>果然天下無免費的午餐…</p><hr><p>Prometheus 的alert寫法:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">cpu_credit</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - alert:</span> <span class="string">CPUCreditTooHigh</span></span><br><span class="line">    <span class="comment"># count the rate (per second) of last 2 hour. if the rate is less than 0 that means the cpu usage is dropping</span></span><br><span class="line">    <span class="comment"># May need to alter to see if the alerts send too rapidly</span></span><br><span class="line"><span class="attr">    expr:</span> <span class="string">avg</span> <span class="string">by</span> <span class="string">(instance_id)</span> <span class="string">(rate(aws_ec2_cpucredit_balance_average[2h]))</span> <span class="string">&lt;</span> <span class="number">0</span></span><br><span class="line"><span class="attr">    for:</span> <span class="number">2</span><span class="string">h</span></span><br><span class="line"><span class="attr">    labels:</span></span><br><span class="line"><span class="attr">      severity:</span> <span class="string">critical</span></span><br><span class="line"><span class="attr">    annotations:</span></span><br><span class="line"><span class="attr">      summary:</span> <span class="string">"CPU credit is running low on <span class="template-variable">&#123;&#123;$labels.instace_id&#125;&#125;</span>"</span></span><br></pre></td></tr></table></figure></p><hr><h4 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h4><ul><li><a href="https://github.com/prometheus/cloudwatch_exporter" target="_blank" rel="noopener">https://github.com/prometheus/cloudwatch_exporter</a></li><li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html</a></li><li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances-monitoring-cpu-credits.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances-monitoring-cpu-credits.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;公司用的kubernetes nodes大部份都是t2 type&lt;br&gt;好處是便宜、彈性大，但壞處也相當明顯&lt;br&gt;當CPU使用率比CPU credit回復的速度慢時，有機會導致cpu credit變成0(或者相當接近0)&lt;br&gt;導致該節點的CPU效能降到極低，大部份進程都會卡住甚至當機&lt;br&gt;這個情況已經發生過不只一次&lt;br&gt;例如在某個node上的rabbitmq(對，沒有用到dedicated 的node)&lt;br&gt;因為有個chromium的pod在同一機器上跑，而且他是以cron job形式去跑，再加上有該死bug，亦沒有設定retry count&lt;br&gt;結果就是山積了一堆job在同一個node上不停跑&lt;br&gt;過了幾天整個CPU credit變成0，rabbitmq掛掉&lt;br&gt;很多其他pod也因此卡死(或者不斷重啟)&lt;/p&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/tags/kubernetes/"/>
    
      <category term="aws" scheme="https://blog.nandiheath.com/tags/aws/"/>
    
      <category term="prometheus" scheme="https://blog.nandiheath.com/tags/prometheus/"/>
    
      <category term="t2.medium" scheme="https://blog.nandiheath.com/tags/t2-medium/"/>
    
      <category term="ec2" scheme="https://blog.nandiheath.com/tags/ec2/"/>
    
  </entry>
  
  <entry>
    <title>Cityline搶飛</title>
    <link href="https://blog.nandiheath.com/2018/08/02/cityline-bot/"/>
    <id>https://blog.nandiheath.com/2018/08/02/cityline-bot/</id>
    <published>2018-08-02T03:02:58.000Z</published>
    <updated>2019-09-18T09:13:44.709Z</updated>
    
    <content type="html"><![CDATA[<p>難得有演唱會想看，但不得不說Cityline的網站真的很垃圾…<br>在進入購票頁之前竟然加了一版”忙碌中”…<br>把用戶先卡住了，需要你手動去點那個”retry”按鈕<br>唯有寫個小程序去一直刷…<br><img src="/images/cityline-bot-0.png" alt=""></p><a id="more"></a><hr><h3 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h3><h4 id="下載這個chrome-plugin"><a href="#下載這個chrome-plugin" class="headerlink" title="下載這個chrome plugin"></a>下載<a href="https://chrome.google.com/webstore/detail/user-javascript-and-css/nbhcbdghjpllgmfilhnhkllmkecfmpld?hl=en" target="_blank" rel="noopener">這個chrome plugin</a></h4><p><img src="/images/cityline-bot-1.png" alt=""></p><ol start="2"><li>在cityline的網頁中打開這個plugin</li><li>勾選javascript 及 jqeury3</li></ol><p><img src="/images/cityline-bot-2.png" alt=""></p><ol start="4"><li>把下面這段程式碼貼上去</li></ol><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> PAGE_YOU_DONT_WANT_TO_SEE = <span class="string">'busy.html'</span>;</span><br><span class="line"><span class="keyword">const</span> RETRY_INTERVAL_IN_MS = <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Only execute one time</span></span><br><span class="line">setTimeout(<span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// only applicable to busy.html</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">window</span>.location.href.indexOf(PAGE_YOU_DONT_WANT_TO_SEE) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Enable the fucking retry button and click it</span></span><br><span class="line">    $(<span class="string">"#btn-retry-en-1"</span>).prop(<span class="string">'disabled'</span>, <span class="literal">false</span>);</span><br><span class="line">    $(<span class="string">"#btn-retry-en-1"</span>).click();</span><br><span class="line">  &#125;</span><br><span class="line">&#125; , RETRY_INTERVAL_IN_MS);</span><br></pre></td></tr></table></figure><p>這個小程序會每隔1秒檢查你當下的網址<br>當發覺你被彈去了<strong>正在繁忙</strong>這一頁時<br>就會幫你點重刷按鈕</p><hr><p>但可惜到最後仍然買不到票……</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;難得有演唱會想看，但不得不說Cityline的網站真的很垃圾…&lt;br&gt;在進入購票頁之前竟然加了一版”忙碌中”…&lt;br&gt;把用戶先卡住了，需要你手動去點那個”retry”按鈕&lt;br&gt;唯有寫個小程序去一直刷…&lt;br&gt;&lt;img src=&quot;/images/cityline-bot-0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="dev" scheme="https://blog.nandiheath.com/categories/dev/"/>
    
    
      <category term="javascript" scheme="https://blog.nandiheath.com/tags/javascript/"/>
    
      <category term="bot" scheme="https://blog.nandiheath.com/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>Mac中的Cassandra塞爆了整個hard disk</title>
    <link href="https://blog.nandiheath.com/2018/07/30/mac-cassandra-disk-full/"/>
    <id>https://blog.nandiheath.com/2018/07/30/mac-cassandra-disk-full/</id>
    <published>2018-07-30T05:01:06.000Z</published>
    <updated>2019-09-18T09:13:44.716Z</updated>
    
    <content type="html"><![CDATA[<p>原因是cassandra 的commit log 因為不知名的原因(可能是被拔掉電源之後的failover?)<br>不斷增加commit log，導致短短兩天把整個硬碟都塞爆了(~630GB)<br>更加令到mac中的account整個消失掉<br>所以在mac中安裝cassandra緊記要limit commit log 的size ..</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Edit cassandra config file</span></span><br><span class="line">vi /usr/<span class="built_in">local</span>/etc/cassandra/cassandra.yaml</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&gt; cassandra.yaml:</span><br><span class="line"></span><br><span class="line"><span class="comment"># uncomment the following line to limit the total file size</span></span><br><span class="line">commitlog_total_space_in_mb: 8192</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原因是cassandra 的commit log 因為不知名的原因(可能是被拔掉電源之後的failover?)&lt;br&gt;不斷增加commit log，導致短短兩天把整個硬碟都塞爆了(~630GB)&lt;br&gt;更加令到mac中的account整個消失掉&lt;br&gt;所以在mac中安裝ca
      
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
    
      <category term="cassandra" scheme="https://blog.nandiheath.com/tags/cassandra/"/>
    
  </entry>
  
  <entry>
    <title>linux底下的logrotate</title>
    <link href="https://blog.nandiheath.com/2018/05/14/nginx-log-rotate/"/>
    <id>https://blog.nandiheath.com/2018/05/14/nginx-log-rotate/</id>
    <published>2018-05-13T19:29:30.000Z</published>
    <updated>2019-09-18T09:13:44.716Z</updated>
    
    <content type="html"><![CDATA[<p>因為之前把一堆東西都加到去nginx的access log裡去(headers/device_id/etc.)<br>結果超巨量的log把硬碟整個塞爆了…<br>所以就研究了下有沒有簡單的log rotation方案可以用</p><h2 id="Linux下的logrotate"><a href="#Linux下的logrotate" class="headerlink" title="Linux下的logrotate"></a>Linux下的logrotate</h2><p>linux上本身已有的logrotate功能<br>簡單設定就可以自動每天進行log rotation</p><h3 id="設定"><a href="#設定" class="headerlink" title="設定"></a>設定</h3><p>新增一個設定檔到 /etc/logrotate.d/nginx</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/var/log/nginx/*.log &#123;</span><br><span class="line">  daily # 每天跑一次</span><br><span class="line">  compress # 壓縮成gz</span><br><span class="line">  delaycompress </span><br><span class="line">  rotate 3 # 每3輪就會rotate一次</span><br><span class="line">  missingok # 不存在也是OK的！</span><br><span class="line">  nocreate</span><br><span class="line">  sharedscripts</span><br><span class="line">  postrotate # rotate完之後的動作</span><br><span class="line">    [ -f /var/run/nginx.pid ] &amp;&amp; kill -USR1 `cat /var/run/nginx.pid`</span><br><span class="line">  endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><p>留意kill -USR1 nginx不是要關掉nginx，而是透過singal去通知nginx 重開log file<br>直接跑以下命令運行測試</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">logrotate -f -v /etc/logrotate.d/nginx</span><br></pre></td></tr></table></figure><p>成功後就會看到一個access.log.1或者access.log.2.gz</p><h2 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h2><ul><li><a href="http://nginx.org/en/docs/control.html" target="_blank" rel="noopener">http://nginx.org/en/docs/control.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因為之前把一堆東西都加到去nginx的access log裡去(headers/device_id/etc.)&lt;br&gt;結果超巨量的log把硬碟整個塞爆了…&lt;br&gt;所以就研究了下有沒有簡單的log rotation方案可以用&lt;/p&gt;
&lt;h2 id=&quot;Linux下的logrotate&quot;&gt;&lt;a href=&quot;#Linux下的logrotate&quot; class=&quot;headerlink&quot; title=&quot;Linux下的logrotate&quot;&gt;&lt;/a&gt;Linux下的logrotate&lt;/h2&gt;&lt;p&gt;linux上本身已有的logrotate功能&lt;br&gt;簡單設定就可以自動每天進行log rotation&lt;/p&gt;
&lt;h3 id=&quot;設定&quot;&gt;&lt;a href=&quot;#設定&quot; class=&quot;headerlink&quot; title=&quot;設定&quot;&gt;&lt;/a&gt;設定&lt;/h3&gt;&lt;p&gt;新增一個設定檔到 /etc/logrotate.d/nginx&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/var/log/nginx/*.log &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  daily # 每天跑一次&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  compress # 壓縮成gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  delaycompress &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  rotate 3 # 每3輪就會rotate一次&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  missingok # 不存在也是OK的！&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  nocreate&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  sharedscripts&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  postrotate # rotate完之後的動作&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    [ -f /var/run/nginx.pid ] &amp;amp;&amp;amp; kill -USR1 `cat /var/run/nginx.pid`&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  endscript&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="devops" scheme="https://blog.nandiheath.com/categories/devops/"/>
    
      <category term="kubernetes" scheme="https://blog.nandiheath.com/categories/devops/kubernetes/"/>
    
    
      <category term="nginx" scheme="https://blog.nandiheath.com/tags/nginx/"/>
    
      <category term="logrotate" scheme="https://blog.nandiheath.com/tags/logrotate/"/>
    
  </entry>
  
</feed>
